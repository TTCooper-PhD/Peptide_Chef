### Data Handling
import numpy as np
import pandas as pd
from pandas import ExcelWriter
import re
import itertools as it
from collections import deque
from itertools import combinations
from urllib.request import urlretrieve
import gzip
from functools import lru_cache
import json


# File Handling Functions
class Cookbook()

    def __init__(self,homebrew=False,len_min=7,len_max=60,db_url=None,species=None):
        self.homebrew=homebrew
        self.takeout=True
        self.url=db_url
        self.len_min=len_min
        self.len_max=len_max
        self.species=None

    def FastaFood(self,measure=False,target=None):
        #Use to import fasta.gz files directly from uniprot (Takeout) with a provided url (Default is Human) or from local folder using homebrew hyperparameter.
        # Takeout is default, Takeout must be switched to False for Homebrew to be True.
        # accepts Uniprot format
        ingredients=list()
        if url == None:
            url="https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/Eukaryota/UP000005640/UP000005640_9606.fasta.gz"
        if (self.homebrew == True) & (self.takeout==True):
            print("Only one method (homebrew/takeout) can == True...")
            print ("Takeout will be automatically selected...")
        if takeout is True:
            homebrew=False
            print('Downloading the FASTA file from url...')
            urlretrieve(self.url,'temp.fasta.gz')
            print('Unzipping...')
            with gzip.open('temp.fasta.gz', mode='rt') as gzfile:
                for info, contents in fasta.FASTA(gzfile):
                    taste=list((info,contents))
                    ingredients.append(taste)
                    recipie=pd.DataFrame(ingredients,columns=['ID','Peptide'])
            print("Takeout is Done!")
        if homebrew is True:
            if self.species == None:
                print("Provide Species identification. This will be the name of the local FASTA file.")
            print("Downloading the FASTA file from local flle...")
            book = str(Species+".fasta")
            recipie=pd.DataFrame()
            print("Serving up a homebrew...")
            with fasta.read(book) as menu:
                for info, contents in menu:
                    taste=list((info,contents))
                    ingredients.append(taste)
                    recipie=pd.DataFrame(ingredients,columns=['ID','Peptide'])
            print("Homebrow is Done!")
        recipie[['db', 'UniprotID','ID2']] = recipie['ID'].str.split('|', 2, expand=True)
        recipie[['Gene','Identification']] = recipie['ID2'].str.split('_', 1, expand=True)
        recipie.drop(columns=['ID', 'ID2',"db"], inplace=True)
        if measure == True:

             print("<easuring total protein length")
            recipie["Protein_Length"]=recipie["Peptide"].str.len()
        print("Here ya go boss!")
        recipie.name=f"{self.species}_Proteome"
        return(recipie)


    def Outpasta_Excel(list_dfs, xls_path):
        i=len(list_dfs)
        with ExcelWriter(xls_path) as writer:
            for n, df in enumerate(list_dfs):
                df.to_excel(writer,'sheet%s' % n)
            writer.save()
        print(f"Good to go Boss, {i} xlsx files(s) Exported")

    def Outpasta_JSON(list_dfs=None,list_dic=None,name_list=None):
        if list_dic=None and list_dfs=None and name_list=None:
            raise ValueError("Need to supply list of dictionary or dataframes, in addition to name_list of equal length")
        elif list_dic != None:
            i=len(list_dic)
            for dic,name in zip (list_dic):
                with (f"{name}.json","w") as j:
                    json.dump(df,j)
        else:
            i=len(list_dfs)
            for df,name in zip(list_dfs,name_list):
                with (f"{name}.json","w") as j:
                    json.dump(df,j)
        print(f"Good to go Boss, {i} JSON files(s) Exported")
        
    def PEAKS_Sampler(csv,drop_OG=True):
        df=pd.read_csv(csv)
        df[["Protein","Y"]]=df['Protein Accession'].str.split("|",1,expand=True)
        df[["Gene","Species"]]=df['Y'].str.split("_",1,expand=True)
        if drop_OG==True:
            df.drop(columns=['Y', 'Protein Accession',"Found By"], inplace=True)
        else:
            df.drop(columns=['Y',"Found By"], inplace=True)
        return(df)

    def Peptide_Origin(origin,target,Origin_Key=None,Target_Key=None,Origin_Label=None, Target_Label=None):
        # primarily used to transfer whole protein measurments (i.e. aa_length) to data_frame with peptide products. Origin_Key is
        # is used to find 'Merge' points (Target_Key) regardless of frequency (likely multiple peptides for one key/protein).Label is used
        # capture information (peptide lenght, sequence, etc) from origin to target. New_Label is optional, default uses origin label to
        # label newly created target column. 
        labeler=origin.set_index(Origin_Key).to_dict()[Origin_Label]
        if Target_Label == None:
            target[Origin_Label] = target[Target_Key].map(labeler)
        else:
            target[Target_Label] = target[Target_Key].map(labeler)
        return target

    def Pep2Pro(protein,peptides):
        protein = re.sub(r'[^A-Z]', '', protein)
        mask = np.zeros(len(protein), dtype=np.int8)
        for peptide in peptides:
            indices = [m.start() for m in re.finditer(
                '(?={})'.format(re.sub(r'[^A-Z]', '', peptide)), protein)]
            for i in indices:
                mask[i:i + len(peptide)] = 1
        return mask.sum(dtype=float) / mask.size
