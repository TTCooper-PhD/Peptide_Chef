{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peptide Chef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by: Tyler T. Cooper, PhD (2021)\n",
    "# Tools to Analyze Peptides and Amino Acid Compositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import openpyxl\n",
    "import re\n",
    "import pyteomics\n",
    "from pyteomics import fasta, parser, electrochem, mass\n",
    "from itertools import combinations\n",
    "from urllib.request import urlretrieve\n",
    "import gzip\n",
    "#dfdfdf\n",
    "#Statistics\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#Figure Generation\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import offsetbox\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.tri import Triangulation\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from IPython.display import Image, display\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "import glob\n",
    "import bioinfokit\n",
    "from bioinfokit import analys, visuz\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Venn Diagrams\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "%matplotlib inline\n",
    "\n",
    "cmap = 'PRGn'\n",
    "fmt='eps'\n",
    "dpi=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Fasta File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/reference_proteomes/Eukaryota/UP000005640/UP000005640_9606.fasta.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use if Fasta file is Local\n",
    "def Cook_Book(Species=None,homebrew=False, takeout=True,url=None,measure=False,target=None):\n",
    "    ingredients=list()\n",
    "    if takeout is True:\n",
    "        homebrew=False\n",
    "        print('Downloading the FASTA file from url...')\n",
    "        urlretrieve(url,'temp.fasta.gz')\n",
    "        print('Unzipping...')\n",
    "        with gzip.open('temp.fasta.gz', mode='rt') as gzfile:\n",
    "            for info, contents in fasta.FASTA(gzfile):\n",
    "                taste=list((info,contents))\n",
    "                ingredients.append(taste)\n",
    "                recipie=pd.DataFrame(ingredients,columns=['ID','Peptide'])\n",
    "        print(\"Takeout is Done!\")\n",
    "    if homebrew is True:\n",
    "        print(\"Downloading the FASTA file from local flle...\")\n",
    "        book = str(Species+\".fasta\")\n",
    "        recipie=pd.DataFrame()\n",
    "        print(\"Serving up a homebrew...\")\n",
    "        with fasta.read(book) as menu:\n",
    "            for info, contents in menu:\n",
    "                taste=list((info,contents))\n",
    "                ingredients.append(taste)\n",
    "                recipie=pd.DataFrame(ingredients,columns=['ID','Peptide'])\n",
    "        print(\"Homebrow is Done!\")\n",
    "    recipie[['db', 'UniprotID','ID2']] = recipie['ID'].str.split('|', 2, expand=True)\n",
    "    recipie[['Gene','Identification']] = recipie['ID2'].str.split('_', 1, expand=True)\n",
    "    recipie.drop(columns=['ID', 'ID2',\"db\"], inplace=True)\n",
    "    if measure == True:\n",
    "        print(\"Measuring...\")\n",
    "        recipie[\"Protein_Length\"]=recipie[target].str.len()\n",
    "    print(\"Here ya go boss!\")\n",
    "    return(recipie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "menu=Cook_Book(takeout=True,url=url, measure=True, target=\"Peptide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(menu.Gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists=[\"ALDH2\",\"BAF\",\"RM52\"]\n",
    "menu.loc[menu['Gene'].isin(lists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "sequence=menu.loc[7421,\"Peptide\"]\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "x=list(it.chain([x.end() for x in re.finditer('([KR](?=[^P]))|((?<=W)K(?=P))|((?<=M)R(?=P))', sequence)],\n",
    "                   [None]))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    'arg-c':         r'R',\n",
    "    'asp-n':         r'\\w(?=D)',\n",
    "    'bnps-skatole' : r'W',\n",
    "    'caspase 1':     r'(?<=[FWYL]\\w[HAT])D(?=[^PEDQKR])',\n",
    "    'caspase 2':     r'(?<=DVA)D(?=[^PEDQKR])',\n",
    "    'caspase 3':     r'(?<=DMQ)D(?=[^PEDQKR])',\n",
    "    'caspase 4':     r'(?<=LEV)D(?=[^PEDQKR])',\n",
    "    'caspase 5':     r'(?<=[LW]EH)D',\n",
    "    'caspase 6':     r'(?<=VE[HI])D(?=[^PEDQKR])',\n",
    "    'caspase 7':     r'(?<=DEV)D(?=[^PEDQKR])',\n",
    "    'caspase 8':     r'(?<=[IL]ET)D(?=[^PEDQKR])',\n",
    "    'caspase 9':     r'(?<=LEH)D',\n",
    "    'caspase 10':    r'(?<=IEA)D',\n",
    "    'chymotrypsin high specificity' : r'([FY](?=[^P]))|(W(?=[^MP]))',\n",
    "    'chymotrypsin low specificity':\n",
    "        r'([FLY](?=[^P]))|(W(?=[^MP]))|(M(?=[^PY]))|(H(?=[^DMPW]))',\n",
    "    'clostripain':   r'R',\n",
    "    'cnbr':          r'M',\n",
    "    'enterokinase':  r'(?<=[DE]{3})K',\n",
    "    'factor xa':     r'(?<=[AFGILTVM][DE]G)R',\n",
    "    'formic acid':   r'D',\n",
    "    'glutamyl endopeptidase': r'E',\n",
    "    'granzyme b':    r'(?<=IEP)D',\n",
    "    'hydroxylamine': r'N(?=G)',\n",
    "    'iodosobenzoic acid': r'W',\n",
    "    'lysc':          r'K',\n",
    "    'ntcb':          r'\\w(?=C)',\n",
    "    'pepsin ph1.3':  r'((?<=[^HKR][^P])[^R](?=[FL][^P]))|'\n",
    "                     r'((?<=[^HKR][^P])[FL](?=\\w[^P]))',\n",
    "    'pepsin ph2.0':  r'((?<=[^HKR][^P])[^R](?=[FLWY][^P]))|'\n",
    "                     r'((?<=[^HKR][^P])[FLWY](?=\\w[^P]))',\n",
    "    'proline endopeptidase': r'(?<=[HKR])P(?=[^P])',\n",
    "    'proteinase k':  r'[AEFILTVWY]',\n",
    "    'staphylococcal peptidase i': r'(?<=[^E])E',\n",
    "    'thermolysin':   r'[^DE](?=[AFILMV])',\n",
    "    'thrombin':      r'((?<=G)R(?=G))|'\n",
    "                     r'((?<=[AFGILTVM][AFGILTVWA]P)R(?=[^DE][^DE]))',\n",
    "    'trypsin':       r'([KR](?=[^P]))|((?<=W)K(?=P))|((?<=M)R(?=P))',\n",
    "    'trypsin_exception': r'((?<=[CD])K(?=D))|((?<=C)K(?=[HY]))|((?<=C)R(?=K))|((?<=R)R(?=[HR]))',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cleaver(sequence, rule, missed_cleavages=0, min_length=None, max_length=None, exception=None):\n",
    "    peptides = []\n",
    "    if rule in rules:\n",
    "        rule = rules[rule]\n",
    "    exception = rules.get(exception, exception)\n",
    "    ml = missed_cleavages + 2\n",
    "    trange = range(ml) #returns range of 0 to ml-1\n",
    "    cleavage_sites = deque([0], maxlen=ml) # returns positions of cleavage sites between each other. \n",
    "    if min_length is None:\n",
    "        min_length = 1\n",
    "    cl = 1\n",
    "    if exception is not None: #locates postion of c-terminal by-product of cleavage. \n",
    "        exceptions = {x.end() for x in re.finditer(exception, sequence)}\n",
    "    for i in it.chain([x.end() for x in re.finditer(rule, sequence)],\n",
    "                   [None]):\n",
    "        if exception is not None and i in exceptions:\n",
    "            continue\n",
    "        cleavage_sites.append(i)\n",
    "#         print(cleavage_sites)\n",
    "        if cl < ml:\n",
    "            cl += 1\n",
    "        for j in trange[:cl - 1]:\n",
    "            seq = sequence[cleavage_sites[j]:cleavage_sites[-1]]\n",
    "            if (seq and len(seq) >= min_length) & (len(seq) < max_length):\n",
    "                peptides.append(seq)\n",
    "    return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_cleavages=0\n",
    "min_length=7\n",
    "max_length=100\n",
    "y=Cleaver(sequence,rule=\"trypsin\",exception=None,missed_cleavages=0,min_length=7,max_length=100)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Variables, Compiliers, Accessory Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessory Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PEAKS_Importer(csv,drop_OG=True):\n",
    "    df=pd.read_csv(csv)\n",
    "    df[[\"Protein\",\"Y\"]]=df['Protein Accession'].str.split(\"|\",1,expand=True)\n",
    "    df[[\"Gene\",\"Species\"]]=df['Y'].str.split(\"_\",1,expand=True)\n",
    "    if drop_OG==True:\n",
    "        df.drop(columns=['Y', 'Protein Accession'], inplace=True)\n",
    "    else:\n",
    "        df.drop(columns=['Y'], inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Excel_Mapper(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,'sheet%s' % n)\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeatWrapper(workbook,old,new,output):\n",
    "    meat = openpyxl.load_workbook(workbook)\n",
    "    wrap = meat[old]\n",
    "    wrap.title = new\n",
    "    meat.save(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sampler(df,toothpicks,samples):\n",
    "    platter = {}\n",
    "    for toothpick, sample in zip(toothpicks, samples):\n",
    "        platter[sample] = df[toothpick]\n",
    "    return platter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ButcherShop(df,target,identifier, rule, min_length=7,exception=None,max_length=100, pH=2.0, min_charge=2,missed=0):\n",
    "    raw=df[[target, identifier]].set_index(identifier).to_dict()[target]\n",
    "    string_catcher=re.compile(r'^([A-Z]+)$')\n",
    "    pep_dict = {}\n",
    "    pep_dict_list = []\n",
    "    print(f'You order is being processed and the butcher is preparing your {rule}-cut protein(s)!')\n",
    "    print(\"The butcher is working...\")\n",
    "    for gene,peptide in raw.items():\n",
    "        pep_dict[gene] = Cleaver(peptide,rule=rule,min_length=min_length,exception=exception,missed_cleavages=missed, max_length=max_length)\n",
    "    for k, lst in pep_dict.items():    \n",
    "        d = {}\n",
    "        for i in range(len(lst)):\n",
    "            d.update({k: lst[i]})\n",
    "            d.update({'gene':k})\n",
    "            d.update({'aa_comp': dict(parser.amino_acid_composition(lst[i]))})\n",
    "            d.update({'peptide': re.findall(string_catcher,lst[i])})\n",
    "            d.update({'Length': len(lst[i])})\n",
    "            d.update({'z': int(round(electrochem.charge(lst[i], pH=pH)))})\n",
    "            d.update({'Mass': int(Peptide_Mass(lst[i]))})\n",
    "            if d[\"z\"] > 0:\n",
    "                d.update({'m/z': d[\"Mass\"]/d['z']})\n",
    "            new_d = d.copy()\n",
    "            pep_dict_list.append(new_d)\n",
    "    print(\"Trimming the cuts....\")\n",
    "    pep_dict_list = [peptide for peptide in pep_dict_list if peptide['Length'] <= int(max_length)]\n",
    "    print(\"Weighing the cuts...\")\n",
    "    pep_dict_list = [peptide for peptide in pep_dict_list if peptide['z'] >= int(min_charge)]\n",
    "    print(f'Order is up! You have acquired {len(pep_dict_list)} peptides that are between {min_length} and {max_length} amino acids!')\n",
    "    return pep_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=ButcherShop(menu,target=\"Peptide\",identifier=\"Gene\", rule=\"trypsin\",missed=2,exception=None,min_length=7,max_length=100)\n",
    "z=DeliShop(z,meat_package=True)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeliShop(z,meat_package=False):\n",
    "    #z = list of dictionaries, keys must be equal thus will drop keys which are not cosistent between dictionaries\n",
    "    # use after ButcherShop\n",
    "    #returns dataframe\n",
    "    key_intersect = set(z[0].keys()).intersection(set(z[1].keys()))\n",
    "    zz = [{key:value for (key,value) in dicts.items() if key in key_intersect} for dicts in z]\n",
    "    ham = pd.DataFrame(zz)\n",
    "    if meat_package == True:\n",
    "        ham_counts=ham.groupby('gene').size().reset_index(name='counts')\n",
    "        ham=ham.merge(ham_counts,how='left', on=['gene'])\n",
    "    ham.drop(ham.columns[0],axis=1,inplace=True)\n",
    "    columns=ham.columns.tolist()\n",
    "    r = re.compile(\"^[pP]\")\n",
    "    P = list(filter(r.match, columns)) \n",
    "    peptide =str(P[0])\n",
    "    ham[peptide]=ham[peptide].apply(\",\".join) # convert list within df to string\n",
    "    return ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meat=ButcherShop(menu,\"Peptide\",\"Gene\",\"thermolysin\")\n",
    "cuts=DeliShop(meat,meat_package=True)\n",
    "cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_Origin(origin,target,Origin_Key=None,Target_Key=None,Origin_Label=None, Target_Label=None):\n",
    "    # primarily used to transfer whole protein measurments (i.e. aa_length) to data_frame with peptide products. Origin_Key is\n",
    "    # is used to find 'Merge' points (Target_Key) regardless of frequency (likely multiple peptides for one key/protein).Label is used\n",
    "    # capture information (peptide lenght, sequence, etc) from origin to target. New_Label is optional, default uses origin label to\n",
    "    # label newly created target column. \n",
    "    labeler=origin.set_index(Origin_Key).to_dict()[Origin_Label]\n",
    "    if Target_Label == None:\n",
    "        target[Origin_Label] = target[Target_Key].map(labeler)\n",
    "    else:\n",
    "        target[Target_Label] = target[Target_Key].map(labeler)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fresh=Peptide_Origin(menu,cuts,Origin_Key=\"Gene\",Target_Key=\"gene\",Origin_Label=\"Protein_Length\",Target_Label=\"OG_LENGTH\")\n",
    "fresh[\"% of Protein\"]= (fresh[\"Length\"]/fresh[\"OG_LENGTH\"])*100\n",
    "fresh.sort_values(by=[\"% of Protein\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_ICE_cloud(df,x=0,target=\"aa_comp\"):\n",
    "    word_could_dict = df[target][x]\n",
    "    wordcloud = WordCloud(width = 500, height = 500,scale=10,prefer_horizontal=1,relative_scaling=1,min_font_size=18,max_font_size=48,font_step=8,\n",
    "                      background_color='white',contour_width=1,contour_color=\"black\" ).generate_from_frequencies(word_could_dict)\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handles Up to 3 Replicates (t_id1-3) per Selection, used for removing amino acids from N-terminal during PEAKS exports with enzyme that cleave at C-terminal. \n",
    "#Can be used to remove M from N-terminal of peptides produced by enzymes which cleave at N-terminal of target aa. \n",
    "def Butcher(df,ident1=None,ident2=None,ident3=None,t_id1=None,t_id2=None,t_id3=None,t_value=0,acid=[\"J\",\"Z\"],labels=list(),excel_mapper=True,excel_name=None):\n",
    "    raw=df.loc[:,df.columns.str.contains(ident1)]\n",
    "    tag=df[labels]\n",
    "    raw = pd.concat([raw, tag], axis=1)\n",
    "    raw[\"Peptide\"]= raw[\"Peptide\"].str.replace('\\W+',\"\")\n",
    "    raw[\"Peptide\"]= raw[\"Peptide\"].str.replace('\\d+',\"\")\n",
    "    raw[\"Peptide\"]= raw[\"Peptide\"].apply(lambda x : x[1:] if x.startswith(tuple(acid)) else x)\n",
    "    cuts=raw.loc[:,raw.columns.str.contains(ident2)]\n",
    "    if ident3 != None:\n",
    "        cuts=cuts.loc[:,cuts.columns.str.contains(ident3)]\n",
    "    cuts = pd.concat([cut, tag], axis=1)\n",
    "    blade = cuts.filter(regex=r'^AREA').isin(['0']).all(axis=1)\n",
    "    cuts=cuts.loc[~blade]\n",
    "    cuts.reset_index(inplace=True)\n",
    "    excels=[raw,cuts]\n",
    "    Excel_Mapper(excels,excel_name +\".xlsx\")\n",
    "    return raw, cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_ICE_bar(df,x=0,target=None,lock=None,key=None):\n",
    "    test_dict=df.loc[df[lock] == key][target].iloc[x]\n",
    "    x=list(test_dict.keys())\n",
    "    y=list(test_dict.values())\n",
    "    plt.bar(x,y, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_ICE_plot(df,x=0,target=None,lock=None,key=None):\n",
    "    test_dict=df.loc[df[lock] == key][target].iloc[x]\n",
    "    x=list(test_dict.keys())\n",
    "    y=list(test_dict.values())\n",
    "    plt.plot(x,y, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Peptide_ICE_plot(fresh,x=0,target=\"aa_comp\", lock=\"gene\",key=\"LHDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_Wash(peptide,ccut=None, PEAKS=False):\n",
    "    if ccut is None:\n",
    "        peptide = peptide.str.replace('\\W+','')\n",
    "        peptide = peptide.str.replace('\\d+','')\n",
    "    elif ccut == \"Trypsin\":\n",
    "        x=[ 'R', 'K']\n",
    "        if PEAKS:\n",
    "            peptide= peptide.apply(lambda x : x[1:] if x.startswith(tuple(x)) else x)\n",
    "        peptide = peptide.str.replace('\\W+','')\n",
    "        peptide = peptide.str.replace('\\d+','')\n",
    "        return(peptide)\n",
    "    elif ccut == \"AspN\":\n",
    "        x=['A', 'R', 'N','D', 'C', 'Q','E', 'G', 'H',\n",
    "             'I', 'L', 'K', 'F', 'P',\n",
    "             'S', 'T', 'W','Y', 'V']\n",
    "        if PEAKS:\n",
    "            peptide= peptide.apply(lambda x : x[1:] if x.startswith(tuple(x)) else x)\n",
    "        peptide = peptide.str.replace('\\W+','')\n",
    "        peptide = peptide.str.replace('\\d+','')\n",
    "        return(peptide)\n",
    "    elif ccut == \"GluC\":\n",
    "        x=['E']\n",
    "        if PEAKS:\n",
    "            peptide= peptide.apply(lambda x : x[1:] if x.startswith(tuple(x)) else x)\n",
    "        peptide = peptide.str.replace('\\W+','')\n",
    "        peptide = peptide.str.replace('\\d+','')\n",
    "        return(peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_IPC(peptide,start_pH=6.51,Epsilon=0.01,):\n",
    "    IPC_score={'Cterm': 2.383, 'pKAsp': 3.887, 'pKGlu': 4.317, 'pKCys': 8.297, 'pKTyr': 10.071, 'pk_his': 6.018, 'Nterm': 9.564, 'pKLys': 10.517, 'pKArg': 12.503}\n",
    "    pKCterm = IPC_score['Cterm']\n",
    "    pKAsp = IPC_score['pKAsp']\n",
    "    pKGlu = IPC_score['pKGlu']\n",
    "    pKCys = IPC_score['pKCys']\n",
    "    pKTyr = IPC_score['pKTyr']\n",
    "    pKHis = IPC_score['pk_his']\n",
    "    pKNterm = IPC_score['Nterm']\n",
    "    pKLys = IPC_score['pKLys'] \n",
    "    pKArg = IPC_score['pKArg']\n",
    "    pH = start_pH      \n",
    "    pHprev = 0.0         \n",
    "    pHnext = 14.0        \n",
    "    E = Epsilon  \n",
    "    temp = 0.01\n",
    "    nterm=peptide[0]\n",
    "    cterm=peptide[-1]\n",
    "#will now cycle through all peptides until a pH within the epsilon is found       \n",
    "    while 1:             \n",
    "        QN1=-1.0/(1.0+pow(10,(pKCterm-pH)))                                        \n",
    "        QN2=-peptide.count('D')/(1.0+pow(10,(pKAsp-pH)))           \n",
    "        QN3=-peptide.count('E')/(1.0+pow(10,(pKGlu-pH)))           \n",
    "        QN4=-peptide.count('C')/(1.0+pow(10,(pKCys-pH)))           \n",
    "        QN5=-peptide.count('Y')/(1.0+pow(10,(pKTyr-pH)))        \n",
    "        QP1=peptide.count('H')/(1.0+pow(10,(pH-pKHis)))            \n",
    "        QP2=1.0/(1.0+pow(10,(pH-pKNterm)))                \n",
    "        QP3=peptide.count('K')/(1.0+pow(10,(pH-pKLys)))           \n",
    "        QP4=peptide.count('R')/(1.0+pow(10,(pH-pKArg)))            \n",
    "        NQ=QN1+QN2+QN3+QN4+QN5+QP1+QP2+QP3+QP4\n",
    "        \n",
    "        if NQ<0.0:                                  \n",
    "            temp = pH\n",
    "            pH = pH-((pH-pHprev)/2.0)\n",
    "            pHnext = temp\n",
    "\n",
    "        else:\n",
    "            temp = pH\n",
    "            pH = pH + ((pHnext-pH)/2.0)\n",
    "            pHprev = temp\n",
    "#terminal condition, finding pI with given precision defined by Epsilon\n",
    "        if (pH-pHprev<E) and (pHnext-pH<E): \n",
    "            return pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_ICEmaker(peptide,excel_name=\"Test\",freeze_it=0,cut_it=6):\n",
    "    ice=peptide.str.slice(freeze_it,cut_it)\n",
    "    ice_ice = ice.str.slice(freeze_it,cut_it)\n",
    "    ice_ice.to_excel('ICE '+excel_name+\".xlsx\")\n",
    "    return ice_ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_Neutral_pH(peptide):\n",
    "    z_dict = {'E': -1, 'D': -1, 'K': 1, 'R': 1} \n",
    "    charge = [z_dict.get(aa, 0.0) for aa in peptide]\n",
    "    spark=sum(charge)\n",
    "    return(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_Gravy(peptide):\n",
    "    hydro = {     \"A\": 1.800,\n",
    "    \"R\": -4.500,\n",
    "    \"N\": -3.500,\n",
    "    \"D\": -3.500,\n",
    "    \"C\": 2.500,\n",
    "    \"Q\": -3.500,\n",
    "    \"E\": -3.500,\n",
    "    \"G\": -0.400,\n",
    "    \"H\": -3.200,\n",
    "    \"I\": 4.500,\n",
    "    \"L\": 3.800,\n",
    "    \"K\": -3.900,\n",
    "    \"M\": 1.900,\n",
    "    \"F\": 2.800,\n",
    "    \"P\": -1.600,\n",
    "    \"S\": -0.800,\n",
    "    \"T\": -0.700,\n",
    "    \"W\": -0.900,\n",
    "    \"Y\": -1.300,\n",
    "    \"V\": 4.200,\n",
    "    }\n",
    "    hydro_list = [hydro.get(aa,0.0)for aa in peptide]\n",
    "    hydro_sum=sum(hydro_list)\n",
    "    gravy=hydro_sum/len(hydro_list)\n",
    "    return gravy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Peptide_Inspector(df,target,new_column=None):\n",
    "    all_data = []\n",
    "    for peptide in df[target]:\n",
    "        temp=dict(parser.amino_acid_composition(peptide))\n",
    "        all_data.append(temp)\n",
    "    df[new_column]=all_data\n",
    "    print(f\"Peptide inspection is completed! Dictionaries are stored under {new_column} in dataframe!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Marinate (df,target,length,IPC=False,Hydro=False,GRAVY=False,NeutralZ=False,Peptide_Inspector=False):\n",
    "    print(\"Marinating peptides...\")\n",
    "    if IPC is True:\n",
    "        df[\"IPC\"]=df[target].apply(Peptide_IPC)\n",
    "        print(\"IPC calculated!\")\n",
    "    if GRAVY is True:\n",
    "        df[\"Hydro_Sum\"]=df[target].apply(Peptide_Gravy)\n",
    "        print(\"Its all GRAVY Baby!\")\n",
    "    if NeutralZ is True:\n",
    "        df[\"Neutral_Z\"]=df[target].apply(Peptide_Neutral_pH)\n",
    "        print(\"Charge at Neutral pH added!\")\n",
    "    print(\"Peptides have been marinated!\")\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wishbone(df,bone,split):\n",
    "    x=df[bone].value_counts()\n",
    "    x2=pd.DataFrame(x,columns=[bone])\n",
    "    x3= x2.loc[(x2[bone])>int(split)]\n",
    "    x3z=len(x3)\n",
    "    x4=x3z/len(x2)*100\n",
    "    print(f\"The number of proteins with > {split} peptides : %.1f\" % x3z)\n",
    "    print(f\"Ratio of Proteins with > {split} Peptides Identified: %.3f\" % x4)\n",
    "    return x3,x3z,x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sweet_N_Sour(set1,set2):\n",
    "    common_IDs=list(set(set1)&set(set2))\n",
    "    common=len(common_IDs)\n",
    "    unique=len(list(set(set1)^set(set2)))\n",
    "    unique_set1=list(set(set1)-set(set2))\n",
    "    unique_set2=list(set(set2)-set(set1))\n",
    "    set1_count=len(unique_set1)\n",
    "    set2_count=len(unique_set2)\n",
    "    Ratio=(unique/(common+unique))*100\n",
    "    print(f\"The number of common peptides is: %.3f\" % common)\n",
    "    print(f\"The number of unique peptides in set1 is: %.3f\" % set1_count)\n",
    "    print(f\"The number of unique peptides in set1 is: %.3f\" % set2_count)\n",
    "    print(f\"The Ratio of Unique to Common proteins is: %.3f\" % Ratio)\n",
    "    return common_IDs,unique_set1, unique_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrPie(df,apples,figsize=(16,8),cmap='Blues',title=\"Title\",fontsize=18,pad=16,save_name=\"Heat_Test\",dpi=600,fmt='eps'):\n",
    "    og_corr=df[apples]\n",
    "    plt.figure(figsize=figsize)\n",
    "    mask=np.triu(np.ones_like(og_corr.corr(), dtype=np.bool))\n",
    "    heatmap=heatmap = sns.heatmap(og_corr.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap=cmap)\n",
    "    heatmap.set_title(title, fontdict={'fontsize':fontsize}, pad=pad)\n",
    "    plt.savefig(save_name,format=fmt,dpi=dpi,bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeddingCake(df,x,y,z,dpi=300,s=12,alpha=0.3,edgecolor='k',color=\"blue\",my_viewx=20,my_viewy=50,\n",
    "               xlabel=\"Parameter xlabel\",ylabel=\"Parameter ylabel\",zlabel=\"Parameter zlabel\",fmt='png',\n",
    "               figx=10,figy=10,xmin=0,xmax=1000,ymin=0,ymax=1000,zmin=0,zmax=1000):\n",
    "    fig = plt.figure(figsize=(figx,figy),dpi=dpi)\n",
    "    ax = fig.gca(projection='3d')\n",
    "    X = df[x]\n",
    "    Y = df[y]\n",
    "    Z = df[z]\n",
    "    ax.scatter(X,Y,Z,color=color,s=s,alpha=alpha,edgecolor=edgecolor)\n",
    "    ax.view_init(my_viewx,my_viewy)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_zlabel(zlabel)\n",
    "    ax.xaxis._axinfo[\"grid\"].update({\"linewidth\":1, \"color\" : \"grey\"})\n",
    "    ax.yaxis._axinfo[\"grid\"].update({\"linewidth\":1, \"color\" : \"grey\"})\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] = \"k\"\n",
    "    ax.zaxis._axinfo[\"grid\"]['linestyle'] = \"--\"\n",
    "    ax.set_ylim3d(ymin,ymax)\n",
    "    ax.set_xlim3d(xmin,xmax)\n",
    "    ax.set_zlim3d(zmin,zmax)\n",
    "    FigTitle=input('Figure Title:')\n",
    "    plt.savefig(FigTitle,format=fmt,dpi=dpi,bbox_inches=\"tight\")\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cake(df,x,y,dpi=600,s=25,alpha=0.25,edgecolor='k',color=\"blue\",fmt='eps',labsize=18,\n",
    "               figx=10,figy=10,xmin=0,xmax=1000,ymin=0,ymax=1000,xlabel=\"xlabel parameter\",ylabel=\"ylabel parameter\",\n",
    "        loc=2,pad=1,borderpad=1,frameon=True, show=False):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(figx,figy),dpi=dpi)\n",
    "    X = df[x]\n",
    "    Y = df[y]\n",
    "    plt.scatter(X,Y,color=color,s=s, alpha=alpha,edgecolor=edgecolor)\n",
    "    plt.xlabel(xlabel, fontsize=labsize)\n",
    "    plt.ylabel(ylabel, fontsize=labsize)\n",
    "    corr, _ = pearsonr(X, Y)\n",
    "    # loc works the same as it does with figures (though best doesn't work)\n",
    "    # pad=5 will increase the size of padding between the border and text\n",
    "    # borderpad=5 will increase the distance between the border and the axes\n",
    "    # frameon=False will remove the box around the text\n",
    "    anchored_text = AnchoredText('Pearsons correlation: r = %.3f' % corr, loc=loc,pad=pad,borderpad=borderpad,frameon=frameon)\n",
    "    ax.add_artist(anchored_text)\n",
    "    FigTitle=input('Figure Title:')\n",
    "    plt.savefig(FigTitle,format=fmt,dpi=dpi,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CakePop(df,x,xi,y,yi, figx=10,figy=10,dpi=600,font_scale=1.5,figstyle=\"white\",xlabel=\"xlabel\",ylabel=\"ylabel\",labsize=18,\n",
    "           cmapx=-0.3,cmapy=0.0,sizex=10,sizey=200,loc='upper left',pad=1,borderpad=1,frameon=True):\n",
    "    sns.set(font_scale=font_scale)\n",
    "    cake=sns.set_style(figstyle)\n",
    "    cmap = sns.cubehelix_palette(start=cmapx, rot=cmapy, as_cmap=True)\n",
    "    X = df[x]\n",
    "    Y = df[y]\n",
    "    cake=sns.relplot(data=df,\n",
    "    x=X, y=Y,\n",
    "    hue=xi, size=yi,\n",
    "    palette=cmap, sizes=(sizex, sizey))\n",
    "    ax = cake.axes[0,0]\n",
    "    ####\n",
    "    corr, _ = pearsonr(X, Y)\n",
    "    anchored_text = AnchoredText('Pearsons correlation: r = %.3f' % corr, loc=loc, prop=dict(size=labsize*0.5),pad=pad,borderpad=borderpad,frameon=frameon)\n",
    "    ax.add_artist(anchored_text)\n",
    "    ####\n",
    "    plt.xlabel(xlabel, fontsize=labsize)\n",
    "    plt.ylabel(ylabel, fontsize=labsize)\n",
    "    FigTitle=input('Figure Title:')\n",
    "    plt.savefig(FigTitle,format=fmt,dpi=dpi,bbox_inches=\"tight\")\n",
    "    plt.show(cake)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
